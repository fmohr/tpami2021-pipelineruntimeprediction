{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compileQuery(query, vars):\n",
    "    repl = {}\n",
    "    for var in vars:\n",
    "        repl[\"{$\" + str(var) + \"}\"] = vars[var]\n",
    "    qc = query\n",
    "    for match in repl:\n",
    "        qc = qc.replace(match, repl[match])\n",
    "    return str(qc)\n",
    "\n",
    "def getCSVOutputCommand(query, filename):\n",
    "    return \"USE sqlrest_baselearners;\\n\\n\" + query + \"\\nINTO OUTFILE '\" + filename + \"'       FIELDS TERMINATED BY ';' ENCLOSED BY '\\\"' LINES TERMINATED BY '\\\\n';\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries for Atomic Algorithm Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = {\n",
    "    \"progressquery\": \"SELECT '{$ALGORITHM}' as algorithm, open, CONCAT(ROUND(100 * open / total, 2), '%') as 'open (rel)', running, CONCAT(ROUND(100 * running / total, 2), '%') as 'running (rel)', finished, CONCAT(ROUND(100 * finished / total, 2), '%') as 'finished (rel)', failed, total, CONCAT(ROUND(avgRuntimeFinished), 's') as 'Average Time of Finished', CONCAT(ROUND(avgRuntimeFinished * open / running), 's') as 'ETA' FROM (SELECT 'aux' as pk, COUNT(*) as 'open' FROM `evaluations_classifiers_{$ALGORITHM}` WHERE time_started is null) as t1 NATURAL JOIN (SELECT 'aux' as pk, COUNT(*) as 'running' FROM `evaluations_classifiers_{$ALGORITHM}` WHERE time_started is not null and time_end is null) as t2 NATURAL JOIN (SELECT 'aux' as pk, COUNT(*) as finished, AVG(TIMESTAMPDIFF(SECOND, time_started, time_end)) as avgRuntimeFinished  FROM `evaluations_classifiers_{$ALGORITHM}` WHERE time_started is not null and time_end is not null) as t3 NATURAL JOIN (SELECT 'aux' as pk, COUNT(*) as failed FROM `evaluations_classifiers_{$ALGORITHM}` where exception is not null) as t4 NATURAL JOIN (SELECT 'aux' as pk, COUNT(*) as total FROM `evaluations_classifiers_{$ALGORITHM}`) as t5\",\n",
    "    \"basicresults\": \"SELECT openmlid, datapoints + predictedinstances as totalsize, datapoints as fitsize, predictedinstances as applicationsize, seed, '{$ALGORITHM}' as classifier, '' as algorithmoptions, numattributes, numberofcategories, numericattributesafterbinarization, numlabels, numnumericattributes, numsymbolicattributes, attributestocover50pctvariance, attributestocover90pctvariance, attributestocover95pctvariance, attributestocover99pctvariance, totalvariance, traintimeinms as fittime, timeforpredictionsinms as applicationtime, stdinpredictiontimeminms, replace(replace(exception, \\\"\\\\n\\\", \\\"\\\\\\\\n\\\"), \\\"\\\\\\\"\\\", \\\"\\\") as exception FROM `evaluations_classifiers_{$ALGORITHM}` where time_end is not null\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE sqlrest_baselearners;\n",
      "\n",
      "SELECT openmlid, datapoints + predictedinstances as totalsize, datapoints as fitsize, predictedinstances as applicationsize, seed, 'bayesnet' as classifier, '' as algorithmoptions, numattributes, numberofcategories, numericattributesafterbinarization, numlabels, numnumericattributes, numsymbolicattributes, attributestocover50pctvariance, attributestocover90pctvariance, attributestocover95pctvariance, attributestocover99pctvariance, totalvariance, traintimeinms as fittime, timeforpredictionsinms as applicationtime, stdinpredictiontimeminms, replace(replace(exception, \"\\n\", \"\\\\n\"), \"\\\"\", \"\") as exception FROM `evaluations_classifiers_bayesnet` where time_end is not null\n",
      "UNION\n",
      "SELECT openmlid, datapoints + predictedinstances as totalsize, datapoints as fitsize, predictedinstances as applicationsize, seed, 'ibk' as classifier, '' as algorithmoptions, numattributes, numberofcategories, numericattributesafterbinarization, numlabels, numnumericattributes, numsymbolicattributes, attributestocover50pctvariance, attributestocover90pctvariance, attributestocover95pctvariance, attributestocover99pctvariance, totalvariance, traintimeinms as fittime, timeforpredictionsinms as applicationtime, stdinpredictiontimeminms, replace(replace(exception, \"\\n\", \"\\\\n\"), \"\\\"\", \"\") as exception FROM `evaluations_classifiers_ibk` where time_end is not null\n",
      "UNION\n",
      "SELECT openmlid, datapoints + predictedinstances as totalsize, datapoints as fitsize, predictedinstances as applicationsize, seed, 'j48' as classifier, '' as algorithmoptions, numattributes, numberofcategories, numericattributesafterbinarization, numlabels, numnumericattributes, numsymbolicattributes, attributestocover50pctvariance, attributestocover90pctvariance, attributestocover95pctvariance, attributestocover99pctvariance, totalvariance, traintimeinms as fittime, timeforpredictionsinms as applicationtime, stdinpredictiontimeminms, replace(replace(exception, \"\\n\", \"\\\\n\"), \"\\\"\", \"\") as exception FROM `evaluations_classifiers_j48` where time_end is not null\n",
      "UNION\n",
      "SELECT openmlid, datapoints + predictedinstances as totalsize, datapoints as fitsize, predictedinstances as applicationsize, seed, 'kstar' as classifier, '' as algorithmoptions, numattributes, numberofcategories, numericattributesafterbinarization, numlabels, numnumericattributes, numsymbolicattributes, attributestocover50pctvariance, attributestocover90pctvariance, attributestocover95pctvariance, attributestocover99pctvariance, totalvariance, traintimeinms as fittime, timeforpredictionsinms as applicationtime, stdinpredictiontimeminms, replace(replace(exception, \"\\n\", \"\\\\n\"), \"\\\"\", \"\") as exception FROM `evaluations_classifiers_kstar` where time_end is not null\n",
      "INTO OUTFILE 'classifierresults-default.csv'       FIELDS TERMINATED BY ';' ENCLOSED BY '\"' LINES TERMINATED BY '\\n';\n"
     ]
    }
   ],
   "source": [
    "jointQuery = \"\\nUNION\\n\".join([compileQuery(queries[\"basicresults\"], {\"ALGORITHM\": a}) for a in [\"bayesnet\", \"ibk\", \"j48\", \"kstar\"]])\n",
    "print(getCSVOutputCommand(jointQuery, \"classifierresults-default.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT 'bayesnet' as algorithm, open, CONCAT(ROUND(100 * open / total, 2), '%') as 'open (rel)', running, CONCAT(ROUND(100 * running / total, 2), '%') as 'running (rel)', finished, CONCAT(ROUND(100 * finished / total, 2), '%') as 'finished (rel)', failed, total, CONCAT(ROUND(avgRuntimeFinished), 's') as 'Average Time of Finished', CONCAT(ROUND(avgRuntimeFinished * open / running), 's') as 'ETA' FROM (SELECT 'aux' as pk, COUNT(*) as 'open' FROM `evaluations_classifiers_bayesnet` WHERE time_started is null) as t1 NATURAL JOIN (SELECT 'aux' as pk, COUNT(*) as 'running' FROM `evaluations_classifiers_bayesnet` WHERE time_started is not null and time_end is null) as t2 NATURAL JOIN (SELECT 'aux' as pk, COUNT(*) as finished, AVG(TIMESTAMPDIFF(SECOND, time_started, time_end)) as avgRuntimeFinished  FROM `evaluations_classifiers_bayesnet` WHERE time_started is not null and time_end is not null) as t3 NATURAL JOIN (SELECT 'aux' as pk, COUNT(*) as failed FROM `evaluations_classifiers_bayesnet` where exception is not null) as t4 NATURAL JOIN (SELECT 'aux' as pk, COUNT(*) as total FROM `evaluations_classifiers_bayesnet`) as t5\n",
      "UNION\n",
      "SELECT 'ibk' as algorithm, open, CONCAT(ROUND(100 * open / total, 2), '%') as 'open (rel)', running, CONCAT(ROUND(100 * running / total, 2), '%') as 'running (rel)', finished, CONCAT(ROUND(100 * finished / total, 2), '%') as 'finished (rel)', failed, total, CONCAT(ROUND(avgRuntimeFinished), 's') as 'Average Time of Finished', CONCAT(ROUND(avgRuntimeFinished * open / running), 's') as 'ETA' FROM (SELECT 'aux' as pk, COUNT(*) as 'open' FROM `evaluations_classifiers_ibk` WHERE time_started is null) as t1 NATURAL JOIN (SELECT 'aux' as pk, COUNT(*) as 'running' FROM `evaluations_classifiers_ibk` WHERE time_started is not null and time_end is null) as t2 NATURAL JOIN (SELECT 'aux' as pk, COUNT(*) as finished, AVG(TIMESTAMPDIFF(SECOND, time_started, time_end)) as avgRuntimeFinished  FROM `evaluations_classifiers_ibk` WHERE time_started is not null and time_end is not null) as t3 NATURAL JOIN (SELECT 'aux' as pk, COUNT(*) as failed FROM `evaluations_classifiers_ibk` where exception is not null) as t4 NATURAL JOIN (SELECT 'aux' as pk, COUNT(*) as total FROM `evaluations_classifiers_ibk`) as t5\n",
      "UNION\n",
      "SELECT 'j48' as algorithm, open, CONCAT(ROUND(100 * open / total, 2), '%') as 'open (rel)', running, CONCAT(ROUND(100 * running / total, 2), '%') as 'running (rel)', finished, CONCAT(ROUND(100 * finished / total, 2), '%') as 'finished (rel)', failed, total, CONCAT(ROUND(avgRuntimeFinished), 's') as 'Average Time of Finished', CONCAT(ROUND(avgRuntimeFinished * open / running), 's') as 'ETA' FROM (SELECT 'aux' as pk, COUNT(*) as 'open' FROM `evaluations_classifiers_j48` WHERE time_started is null) as t1 NATURAL JOIN (SELECT 'aux' as pk, COUNT(*) as 'running' FROM `evaluations_classifiers_j48` WHERE time_started is not null and time_end is null) as t2 NATURAL JOIN (SELECT 'aux' as pk, COUNT(*) as finished, AVG(TIMESTAMPDIFF(SECOND, time_started, time_end)) as avgRuntimeFinished  FROM `evaluations_classifiers_j48` WHERE time_started is not null and time_end is not null) as t3 NATURAL JOIN (SELECT 'aux' as pk, COUNT(*) as failed FROM `evaluations_classifiers_j48` where exception is not null) as t4 NATURAL JOIN (SELECT 'aux' as pk, COUNT(*) as total FROM `evaluations_classifiers_j48`) as t5\n",
      "UNION\n",
      "SELECT 'kstar' as algorithm, open, CONCAT(ROUND(100 * open / total, 2), '%') as 'open (rel)', running, CONCAT(ROUND(100 * running / total, 2), '%') as 'running (rel)', finished, CONCAT(ROUND(100 * finished / total, 2), '%') as 'finished (rel)', failed, total, CONCAT(ROUND(avgRuntimeFinished), 's') as 'Average Time of Finished', CONCAT(ROUND(avgRuntimeFinished * open / running), 's') as 'ETA' FROM (SELECT 'aux' as pk, COUNT(*) as 'open' FROM `evaluations_classifiers_kstar` WHERE time_started is null) as t1 NATURAL JOIN (SELECT 'aux' as pk, COUNT(*) as 'running' FROM `evaluations_classifiers_kstar` WHERE time_started is not null and time_end is null) as t2 NATURAL JOIN (SELECT 'aux' as pk, COUNT(*) as finished, AVG(TIMESTAMPDIFF(SECOND, time_started, time_end)) as avgRuntimeFinished  FROM `evaluations_classifiers_kstar` WHERE time_started is not null and time_end is not null) as t3 NATURAL JOIN (SELECT 'aux' as pk, COUNT(*) as failed FROM `evaluations_classifiers_kstar` where exception is not null) as t4 NATURAL JOIN (SELECT 'aux' as pk, COUNT(*) as total FROM `evaluations_classifiers_kstar`) as t5\n"
     ]
    }
   ],
   "source": [
    "jointQuery = \"\\nUNION\\n\".join([compileQuery(queries[\"progressquery\"], {\"ALGORITHM\": a}) for a in [\"bayesnet\", \"ibk\", \"j48\", \"kstar\"]])\n",
    "#print(getCSVOutputCommand(jointQuery, \"classifierresults-default.csv\"))\n",
    "print(jointQuery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries for Results of ML-Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compileQuery(query, to, mode):\n",
    "    repl = {\n",
    "        '{$T_EVAL}': VARS[to][mode][\"eval\"],\n",
    "        '{$T_JOBS}': VARS[to][mode][\"jobs\"],\n",
    "        '{$TARGET}': mode\n",
    "    }\n",
    "    qc = queries[query]\n",
    "    for match in repl:\n",
    "        qc = qc.replace(match, repl[match])\n",
    "    return str(qc)\n",
    "\n",
    "def compileJoin(query, to):\n",
    "    q1 = compileQuery(query, to, \"vanilla\")\n",
    "    q2 = compileQuery(query, to, \"guarded\")\n",
    "    return \"SELECT * FROM (\" + q1 + \") as t1 JOIN (\" + q2 + \") as t2 USING(dataset)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARS = {\n",
    "    '1h': {\n",
    "        'vanilla': {\n",
    "            'eval': 'cont_eval_mlplan_1h',\n",
    "            'jobs': 'cont_jobs_mlplan_1h'\n",
    "        },\n",
    "        'guarded': {\n",
    "            'eval': 'cont_eval_mlplan_safeguard_1h',\n",
    "            'jobs': 'cont_jobs_mlplan_safeguard_1h',\n",
    "        } \n",
    "    },\n",
    "    '1d': {\n",
    "        'vanilla': {\n",
    "            'eval': 'cont_eval_mlplan_24h',\n",
    "            'jobs': 'cont_jobs_mlplan_24h'\n",
    "        },\n",
    "        'guarded': {\n",
    "            'eval': 'cont_eval_mlplan_safeguard_24h',\n",
    "            'jobs': 'cont_jobs_mlplan_safeguard_24h',\n",
    "        } \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = {\n",
    "    \"avgSuccessCounts\": 'SELECT dataset, avg(n) as n_{$TARGET}, std(n) as std_{$TARGET} FROM (SELECT experiment_id, COUNT(*) as n FROM `{$T_EVAL}` WHERE status = \"success\" AND thread LIKE \"%worker%\" GROUP by experiment_id) as t natural join {$T_JOBS}  WHERE time_end IS NOT NULL group by dataset',\n",
    "    \"avgSuccessCountsPerThread\": 'SELECT dataset, avg(n) as n_{$TARGET} FROM (SELECT experiment_id, COUNT(*) as n FROM `{$T_EVAL}` WHERE status = \"success\" AND thread LIKE \"%worker%\" GROUP by experiment_id, thread) as t natural join {$T_JOBS}  WHERE time_end IS NOT NULL group by dataset',\n",
    "    \"avgSuccessTimes\": 'SELECT dataset, avg(successtime) as t_{$TARGET} FROM (SELECT experiment_id, dataset, sum(actualFitTime+ actualPredictTime) as successtime FROM `{$T_EVAL}` natural join {$T_JOBS} WHERE time_end IS NOT NULL AND result IS NOT NULL AND status = \"success\" GROUP BY experiment_id) as t GROUP BY dataset',\n",
    "    \"avgSuccessTimesPerThread\": 'SELECT dataset, AVG(successtime) as t_{$TARGET} FROM( SELECT experiment_id, thread, dataset, sum(actualFitTime+ actualPredictTime) * 5 as successtime FROM {$T_EVAL} natural join {$T_JOBS} WHERE time_end IS NOT NULL AND result IS NOT NULL AND status = \"success\" and thread LIKE \"%worker%\" GROUP BY experiment_id, thread) as t2 GROUP BY dataset',\n",
    "    \"avgTimeouts\": 'SELECT * FROM (SELECT dataset, avg(timeoutedevaluations) as timeouts_{$TARGET} FROM (SELECT experiment_id, COUNT(*) as timeoutedevaluations FROM `{$T_EVAL}` WHERE status = \"timeout\" and actualFitTime + actualPredictTime > 60 AND thread LIKE \"%worker%\" GROUP BY experiment_id) as t NATURAL JOIN {$T_JOBS} WHERE time_end IS NOT NULL group by dataset) as t2',\n",
    "    \"avgAvoidances\": 'SELECT dataset, avg(n) as n_{$TARGET} FROM (SELECT experiment_id, COUNT(*) as n FROM `{$T_EVAL}` WHERE status = \"safeguard\" GROUP by experiment_id) as t natural join {$T_JOBS}  WHERE time_end IS NOT NULL group by dataset',\n",
    "    \"avgWorkerTime\": 'SELECT  dataset, avg(avgworktime) FROM (SELECT experiment_id, dataset, avg(worktime) as avgworktime FROM (SELECT experiment_id, dataset, thread, round((MAX(timestamp_found) - min(timestamp_found)) / 1000) as worktime FROM `{$T_EVAL}` natural join {$T_JOBS} where thread LIKE \"%worker%\" GROUP BY experiment_id, thread) as t group by experiment_id) as t2 group by dataset'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Analysis Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM (SELECT dataset, avg(n) as n_vanilla, std(n) as std_vanilla FROM (SELECT experiment_id, COUNT(*) as n FROM `cont_eval_mlplan_1h` WHERE status = \"success\" AND thread LIKE \"%worker%\" GROUP by experiment_id) as t natural join cont_jobs_mlplan_1h  WHERE time_end IS NOT NULL group by dataset) as t1 JOIN (SELECT dataset, avg(n) as n_guarded, std(n) as std_guarded FROM (SELECT experiment_id, COUNT(*) as n FROM `cont_eval_mlplan_safeguard_1h` WHERE status = \"success\" AND thread LIKE \"%worker%\" GROUP by experiment_id) as t natural join cont_jobs_mlplan_safeguard_1h  WHERE time_end IS NOT NULL group by dataset) as t2 USING(dataset)\n"
     ]
    }
   ],
   "source": [
    "print(compileJoin(\"avgSuccessCounts\", \"1h\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM (SELECT dataset, avg(successtime) as t_vanilla FROM (SELECT experiment_id, dataset, sum(actualFitTime+ actualPredictTime) as successtime FROM `cont_eval_mlplan_24h` natural join cont_jobs_mlplan_24h WHERE time_end IS NOT NULL AND result IS NOT NULL AND status = \"success\" GROUP BY experiment_id) as t GROUP BY dataset) as t1 JOIN (SELECT dataset, avg(successtime) as t_guarded FROM (SELECT experiment_id, dataset, sum(actualFitTime+ actualPredictTime) as successtime FROM `cont_eval_mlplan_safeguard_24h` natural join cont_jobs_mlplan_safeguard_24h WHERE time_end IS NOT NULL AND result IS NOT NULL AND status = \"success\" GROUP BY experiment_id) as t GROUP BY dataset) as t2 USING(dataset)\n"
     ]
    }
   ],
   "source": [
    "print(compileJoin(\"avgSuccessTimes\", \"1d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM (SELECT  dataset, avg(avgworktime) FROM (SELECT experiment_id, dataset, avg(worktime) as avgworktime FROM (SELECT experiment_id, dataset, thread, round((MAX(timestamp_found) - min(timestamp_found)) / 1000) as worktime FROM `cont_eval_mlplan_1h` natural join cont_jobs_mlplan_1h where thread LIKE \"%worker%\" GROUP BY experiment_id, thread) as t group by experiment_id) as t2 group by dataset) as t1 JOIN (SELECT  dataset, avg(avgworktime) FROM (SELECT experiment_id, dataset, avg(worktime) as avgworktime FROM (SELECT experiment_id, dataset, thread, round((MAX(timestamp_found) - min(timestamp_found)) / 1000) as worktime FROM `cont_eval_mlplan_safeguard_1h` natural join cont_jobs_mlplan_safeguard_1h where thread LIKE \"%worker%\" GROUP BY experiment_id, thread) as t group by experiment_id) as t2 group by dataset) as t2 USING(dataset)\n"
     ]
    }
   ],
   "source": [
    "print(compileJoin(\"avgWorkerTime\", \"1h\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant Queries for Final Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Avoided Executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQueryForAvgAvoidances(to):\n",
    "       return compileQuery(\"avgAvoidances\", to, \"guarded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT dataset, avg(n) as n_guarded FROM (SELECT experiment_id, COUNT(*) as n FROM `cont_eval_mlplan_safeguard_1h` WHERE status = \"safeguard\" GROUP by experiment_id) as t natural join cont_jobs_mlplan_safeguard_1h  WHERE time_end IS NOT NULL group by dataset\n"
     ]
    }
   ],
   "source": [
    "print(getQueryForAvgAvoidances(\"1h\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Timeouts Per Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQueryForAvgTimeouts(to):\n",
    "       return compileJoin(\"avgTimeouts\", to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM (SELECT * FROM (SELECT dataset, avg(timeoutedevaluations) as timeouts_vanilla FROM (SELECT experiment_id, COUNT(*) as timeoutedevaluations FROM `cont_eval_mlplan_1h` WHERE status = \"timeout\" and actualFitTime + actualPredictTime > 60 AND thread LIKE \"%worker%\" GROUP BY experiment_id) as t NATURAL JOIN cont_jobs_mlplan_1h WHERE time_end IS NOT NULL group by dataset) as t2) as t1 JOIN (SELECT * FROM (SELECT dataset, avg(timeoutedevaluations) as timeouts_guarded FROM (SELECT experiment_id, COUNT(*) as timeoutedevaluations FROM `cont_eval_mlplan_safeguard_1h` WHERE status = \"timeout\" and actualFitTime + actualPredictTime > 60 AND thread LIKE \"%worker%\" GROUP BY experiment_id) as t NATURAL JOIN cont_jobs_mlplan_safeguard_1h WHERE time_end IS NOT NULL group by dataset) as t2) as t2 USING(dataset)\n"
     ]
    }
   ],
   "source": [
    "print(getQueryForAvgTimeouts(\"1h\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Successful Executions Per Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQueryForAvgSuccess(to):\n",
    "       return compileJoin(\"avgSuccess\", to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM (SELECT dataset, avg(n) as n_vanilla FROM (SELECT experiment_id, COUNT(*) as n FROM `cont_eval_mlplan_1h` WHERE status = \"success\" GROUP by experiment_id) as t natural join cont_jobs_mlplan_1h  WHERE time_end IS NOT NULL group by dataset) as t1 JOIN (SELECT dataset, avg(n) as n_guarded FROM (SELECT experiment_id, COUNT(*) as n FROM `cont_eval_mlplan_safeguard_1h` WHERE status = \"success\" GROUP by experiment_id) as t natural join cont_jobs_mlplan_safeguard_1h  WHERE time_end IS NOT NULL group by dataset) as t2 USING(dataset)\n"
     ]
    }
   ],
   "source": [
    "print(getQueryForAvgSuccess(\"1h\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT dataset, avg(n) as n_guarded FROM (SELECT experiment_id, COUNT(*) as n FROM `cont_eval_mlplan_safeguard_1h` WHERE status = \"success\" GROUP by experiment_id) as t natural join cont_jobs_mlplan_safeguard_1h  WHERE time_end IS NOT NULL group by dataset\n"
     ]
    }
   ],
   "source": [
    "print(compileQuery(\"avgSuccess\", \"1h\", \"guarded\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Executions Grouped by Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT dataset, status, avg(c)  FROM (SELECT experiment_id, status, count(*) as c FROM `cont_eval_mlplan_1h` GROUP BY experiment_id, status) as t natural join cont_jobs_mlplan_1h group by dataset, status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avg Time Spent in Executions of different Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avg time used by the workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT dataset, avg(worktime) FROM (SELECT experiment_id, dataset, thread, round((MAX(timestamp_found) - min(timestamp_found)) / 1000) as worktime FROM `cont_eval_mlplan_safeguard_1h` natural join cont_jobs_mlplan_safeguard_1h where thread LIKE \"%worker%\" GROUP BY experiment_id, thread) as t GROUP BY dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get experiments with avg worker time < x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT experiment_id, dataset, avgworktime FROM (SELECT experiment_id, dataset, avg(worktime) as avgworktime FROM (SELECT experiment_id, dataset, thread, round((MAX(timestamp_found) - min(timestamp_found)) / 1000) as worktime FROM `cont_eval_mlplan_safeguard_1h` natural join cont_jobs_mlplan_safeguard_1h where thread LIKE \"%worker%\" GROUP BY experiment_id, thread) as t group by experiment_id) as t2 WHERE avgworktime < 2500 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
