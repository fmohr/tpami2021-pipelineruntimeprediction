{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from commons import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. A Direct Regressor\n",
    "Here we try to build a global model for everything รก la SMAC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (3,21) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dfAtomic = pd.read_csv(\"data/runtimes/runtimes_atomic.csv\")\n",
    "dfAtomic = dfAtomic[dfAtomic[\"error\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPipelines = pd.read_csv(\"data/rawruntimes/pipelines.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPlainAlgorithmName(name):\n",
    "    return name[(name.rfind(\".\")+1):].lower()\n",
    "\n",
    "def getClassifierOptionDF(algo, options = None):\n",
    "    if options is None:\n",
    "        options = []\n",
    "    return explodeAlgorithmOptions(pd.DataFrame([[algo, \" \".join(options)]], columns=[\"algorithm\", \"algorithmoptions\"])).drop(columns=[\"algorithm\", \"algorithmoptions\"]).add_prefix(algo + \"_\")\n",
    "\n",
    "def getPreprocessorOptionDF(algo, options = None):\n",
    "    if options is None:\n",
    "        options = \";\"\n",
    "    elif type(options) != str:\n",
    "        raise Exception(\"Pre-processor options must be a string.\")\n",
    "    return explodeAlgorithmOptions(pd.DataFrame([[algo, options]], columns=[\"algorithm\", \"algorithmoptions\"])).drop(columns=[\"algorithm\", \"algorithmoptions\"]).add_prefix(algo + \"_\")\n",
    "\n",
    "\n",
    "def getVectorialRepresentationofRuntimes(dfPipelines):\n",
    "    \n",
    "    #\n",
    "    dfBasis = pd.DataFrame([], columns=[\"openmlid\", \"numinstances\", \"numattributes\", \"searcher\", \"searcheroptions\", \"evaluator\", \"evaluatoroptions\", \"baseclassifier\", \"baseclassifieroptions\", \"metaclassifier\", \"metaclassifieroptions\", \"fittime\", \"apptimeperkinstances\", \"exception\"])\n",
    "    for algo in algorithms + metalearners:\n",
    "        if algo in classifiers or algo in metalearners:\n",
    "            dfAlgo = getClassifierOptionDF(algo)\n",
    "        if algo in preprocessors:\n",
    "            dfAlgo = getPreprocessorOptionDF(algo)\n",
    "        dfBasis = dfAlgo if dfBasis is None else pd.concat([dfBasis, dfAlgo], axis=0)\n",
    "    dfBasis = dfBasis.drop(index=dfBasis.index)\n",
    "    \n",
    "    pbar = tqdm(total=len(dfPipelines))\n",
    "    for i, row in dfPipelines.iterrows():\n",
    "        setup = eval(row[\"setup\"])\n",
    "        pipelinedescription = setup[\"pipeline\"][\"instructions\"][0][\"arguments\"]\n",
    "        searcherClass = getPlainAlgorithmName(pipelinedescription[0])\n",
    "        searcherParams = pipelinedescription[1]\n",
    "        evaluatorClass = getPlainAlgorithmName(pipelinedescription[2])\n",
    "        evaluatorParams = pipelinedescription[3]\n",
    "        classifierClass = getPlainAlgorithmName(pipelinedescription[4])\n",
    "        classifierParams = pipelinedescription[5]\n",
    "        isMetaLearner = not classifierClass in classifiers\n",
    "        if isMetaLearner:\n",
    "            indexBaseLearnerDescriptionStart = classifierParams.index(\"-W\")\n",
    "            indexBaseLearnerDescriptionStop = (indexBaseLearnerDescriptionStart + classifierParams[indexBaseLearnerDescriptionStart:].index(\"--\") + 1) if \"--\" in classifierParams[indexBaseLearnerDescriptionStart:] else len(classifierParams)\n",
    "            #baseClassifierDescription = classifierParams[indexBaseLearnerDescriptionStart:indexBaseLearnerDescriptionStop]\n",
    "            baseClassifierName = getPlainAlgorithmName(classifierParams[indexBaseLearnerDescriptionStart + 1])\n",
    "            baseClassifierParams = classifierParams[indexBaseLearnerDescriptionStop:]\n",
    "            metaClassifierName = classifierClass\n",
    "            metaClassifierParams = classifierParams[:indexBaseLearnerDescriptionStart]\n",
    "        else:\n",
    "            baseClassifierName = classifierClass\n",
    "            baseClassifierParams = classifierParams\n",
    "            metaClassifierName = np.nan\n",
    "            metaClassifierParams = []\n",
    "            \n",
    "        # compose a dataframe for this row\n",
    "        dfRow = pd.DataFrame([[setup['openmlid'], setup['numinstances'], setup['numattributes'], searcherClass, \" \".join(searcherParams), evaluatorClass, \" \".join(evaluatorParams), baseClassifierName, \" \".join(baseClassifierParams), metaClassifierName, \" \".join(metaClassifierParams), row[\"traintimeinms\"], 1000 * row[\"timeforpredictionsinms\"] / row[\"predictedinstances\"], row[\"exception\"]]], columns=[\"openmlid\", \"numinstances\", \"numattributes\", \"searcher\", \"searcheroptions\", \"evaluator\", \"evaluatoroptions\", \"baseclassifier\", \"baseclassifieroptions\", \"metaclassifier\", \"metaclassifieroptions\", \"fittime\", \"apptimeperkinstances\", \"exception\"])\n",
    "        dfRow = pd.concat([dfRow, getClassifierOptionDF(baseClassifierName, baseClassifierParams)], axis=1)\n",
    "        if (not searcherParams is None and len(searcherParams) > 0) or (not evaluatorParams is None and len(evaluatorParams) > 0):\n",
    "            ppName = searcherClass + \"_\" + evaluatorClass\n",
    "            ppOptions = \" \".join(searcherParams) + \";\" + \" \".join(evaluatorParams)\n",
    "            dfRow = pd.concat([dfRow, getPreprocessorOptionDF(ppName, ppOptions)], axis=1)\n",
    "        \n",
    "        if not metaClassifierParams is None and len(metaClassifierParams) > 0:\n",
    "            dfRow = pd.concat([dfRow, getClassifierOptionDF(metaClassifierName, metaClassifierParams)], axis=1)\n",
    "        \n",
    "        dfBasis = pd.concat([dfBasis, dfRow])\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "        \n",
    "    return dfBasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_vectorial_representation_of_runtimes = False\n",
    "\n",
    "# this takes LONG (can be up to 1d), avoid if not necessary to re-compute\n",
    "if compute_vectorial_representation_of_runtimes:\n",
    "    dfPipelinesConverted = getVectorialRepresentationofRuntimes(dfPipelines[(dfPipelines[\"traintimeinms\"].notna()) | (dfPipelines[\"exception\"].notna())])\n",
    "    dfPipelinesConverted.to_csv(\"data/workdata/pipelines.csv\", sep=\";\", index=False)\n",
    "    dfPipelinesConverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPipelines = pd.read_csv(\"data/workdata/pipelines.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPipelinesMod = dfPipelines.copy()\n",
    "timeouts = (dfPipelines[\"exception\"].notna()) & (dfPipelines[\"exception\"].str.contains(\"Timeout\"))\n",
    "dfPipelinesMod.at[np.where(timeouts)[0], \"fittime\"] = 3600 * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The Composed Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComposedRegressor():\n",
    "    \n",
    "    def __init__(self, dfAtomic):\n",
    "        self.dfAtomic = dfAtomic[[\"algorithm\", \"algorithmoptions\", \"openmlid\", \"fitsize\", \"fitattributes\", \"fittime\", \"applicationtimeperkinstances\"]].copy()\n",
    "        self.dfAtomic[\"msize\"] = self.dfAtomic[\"fitsize\"] * self.dfAtomic[\"fitattributes\"]\n",
    "        self.dfAtomic[\"msize2\"] = self.dfAtomic[\"fitsize\"] * self.dfAtomic[\"fitattributes\"] ** 2\n",
    "        \n",
    "    def predictRuntime(self, openmlid, fitsize, fitattributes, appsize, baselearner, preprocessor=None, metalearner = None):\n",
    "        \n",
    "        hasPreprocessor = not preprocessor is None\n",
    "        hasMetalearner = not metalearner is None\n",
    "        \n",
    "        # build relevant models\n",
    "        models = {\"base\": {}, \"pre\": {}}\n",
    "        for role, algorithm in [(\"base\", baselearner), (\"pre\", preprocessor)]:\n",
    "            if not algorithm is None:\n",
    "                dfTrain = self.dfAtomic[(self.dfAtomic[\"openmlid\"] != openmlid) & (self.dfAtomic[\"algorithm\"] == algorithm[0])]\n",
    "                if len(dfTrain) == 0:\n",
    "                    raise Exception(\"No training examples for openmlid \" + str(openmlid) + \" and baselearner \" + algorithm[0])\n",
    "                X = explodeAlgorithmOptions(dfTrain[[\"algorithm\", \"algorithmoptions\", \"fitsize\", \"fitattributes\"]]).drop(columns=[\"algorithm\", \"algorithmoptions\"])\n",
    "                for att in \"searcheroptions\", \"evaloptions\":\n",
    "                    if att in list(X.columns):\n",
    "                        X = X.drop(columns=[att])\n",
    "                for target in [\"fittime\", \"applicationtimeperkinstances\"]:\n",
    "                    model = sk.ensemble.RandomForestRegressor(n_estimators=10)\n",
    "                    Y = dfTrain[target].values\n",
    "                    #print(dfTrain[\"fittime\"].values)\n",
    "                    model.fit(X, Y)\n",
    "                    models[role][target] = model\n",
    "                    #print(\"Forest trained for \" + role + \" \" + baselearner[0] + \" \" + target + \" using \" + str(len(X)) + \" examples excluding those for dataset \" + str(openmlid))\n",
    "                \n",
    "        # extract meta-features\n",
    "        X = [fitsize, fitattributes]#, fitsize * fitattributes, fitsize * fitattributes ** 2]\n",
    "        \n",
    "        # get pre-processor runtime and estimate of modified data\n",
    "        if hasPreprocessor:\n",
    "            X_params_df = getPreprocessorOptionDF(preprocessor[0], preprocessor[1]).drop(columns=[preprocessor[0] + v for v in [\"_searcheroptions\", \"_evaloptions\"]])\n",
    "            X_params = list(X_params_df.values[0])\n",
    "            runtimePreprocessorFit = models[\"pre\"][\"fittime\"].predict([X + X_params])[0]\n",
    "            runtimePreprocessorApp = models[\"pre\"][\"applicationtimeperkinstances\"].predict([X + X_params])[0] * (fitsize + appsize) / 1000\n",
    "            runtimePreprocessor = runtimePreprocessorFit + runtimePreprocessorApp\n",
    "            if preprocessor[0] + \"_N\" in list(X_params_df.columns):\n",
    "                estimatedNumberOfNewAttributes = min(fitattributes, X_params_df[preprocessor[0] + \"_N\"].values[0])\n",
    "            else:\n",
    "                estimatedNumberOfNewAttributes = fitattributes\n",
    "            X = [X[0], estimatedNumberOfNewAttributes]#, X[0] * estimatedNumberOfNewAttributes, X[0] * estimatedNumberOfNewAttributes**2]\n",
    "        else:\n",
    "            runtimePreprocessor = 0\n",
    "\n",
    "        # if there is a meta-learner, compute dataset meta features for the used base learner\n",
    "        if hasMetalearner:\n",
    "            pass\n",
    "\n",
    "        # get base learner runtimes\n",
    "        #print(\"Predict: \", X, X_params)\n",
    "        #print(\"original data: \" + str(self.dfAtomic[(self.dfAtomic[\"openmlid\"] != openmlid) & (self.dfAtomic[\"algorithm\"] == algorithm[0]) & (self.dfAtomic[\"fitsize\"] == X[0]) & (self.dfAtomic[\"fitattributes\"] == X[1])]))\n",
    "        X_params = list(getClassifierOptionDF(baselearner[0], baselearner[1].split(\" \") if str(baselearner[1]) != \"nan\" else []).values[0])\n",
    "        runtimeBaselearnerFit = models[\"base\"][\"fittime\"].predict([X + X_params])[0]\n",
    "        runtimeBaselearnerApp = models[\"base\"][\"applicationtimeperkinstances\"].predict([X + X_params])[0]\n",
    "        \n",
    "        # consider meta-learner if relevant\n",
    "        totalruntime = runtimePreprocessor\n",
    "        if hasMetalearner:\n",
    "            k, p, q = (1, 2, 3) # get params\n",
    "            totalruntime += k * (runtimeBaselearnerFit + (p+q)/1000 * runtimeBaselearnerApp)\n",
    "        else:\n",
    "            #print(runtimePreprocessor, runtimeBaselearnerFit, runtimeBaselearnerApp)\n",
    "            blruntime = runtimeBaselearnerFit + runtimeBaselearnerApp * (fitsize + appsize) / 1000\n",
    "            totalruntime += blruntime\n",
    "            print(\"PP: \" + str(runtimePreprocessor) + \", BL: \" + str(blruntime))\n",
    "        return totalruntime\n",
    "\n",
    "        \n",
    "dfTest = pd.DataFrame([[100, 100, 1, 0, 1, 0, 0, 0, 0, 12000]], columns = [\"fitsize\", \"fitattributes\", 'D', 'Q_K2', 'Q_Tabu', 'Q_SA', 'Q_LAGDHC', 'Q_TAN', 'Q_HC', 'appsize'])\n",
    "dfTest[\"af1\"] = dfTest[\"fitsize\"] * dfTest[\"fitattributes\"]\n",
    "dfTest[\"af2\"] = dfTest[\"fitsize\"] * dfTest[\"fitattributes\"]**2\n",
    "dfTest = dfTest[[\"fitsize\", \"fitattributes\", \"af1\", \"af2\", 'D', 'Q_K2', 'Q_Tabu', 'Q_SA', 'Q_LAGDHC', 'Q_TAN', 'Q_HC', 'appsize']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Compare the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381800ba72784ec3b290dd728d82f8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5211.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "reg = ComposedRegressor(dfAtomic[(dfAtomic[\"algorithmoptions\"].notna())])\n",
    "\n",
    "COMPARISON = []\n",
    "for (openmlid, fitsize, fitattributes), dfValidation in tqdm(dfPipelinesMod.groupby([\"openmlid\", \"numinstances\", \"numattributes\"])):\n",
    "\n",
    "\n",
    "    dfVectorial = pd.get_dummies(dfPipelinesMod, columns=[\"searcher\", \"evaluator\", \"baseclassifier\", \"metaclassifier\"]).drop(columns=[\"searcheroptions\", \"evaluatoroptions\", \"baseclassifieroptions\", \"metaclassifieroptions\", \"exception\"])\n",
    "    dfVectorial[\"fittime\"] = dfVectorial[\"fittime\"].fillna(3600000)\n",
    "    dfVectorial[\"apptimeperkinstances\"] = dfVectorial[\"apptimeperkinstances\"].fillna(0)\n",
    "    dfVectorial = dfVectorial.fillna(-1)\n",
    "    for pp in preprocessors:\n",
    "        dfVectorial = dfVectorial.drop(columns=[pp + \"_searcheroptions\", pp + \"_evaloptions\"])\n",
    "    \n",
    "    dfValidation = dfVectorial[(dfVectorial[\"openmlid\"] == openmlid) & (dfVectorial[\"numinstances\"] == fitsize) & (dfVectorial[\"numattributes\"] == fitattributes)]\n",
    "    print(len(dfValidation))\n",
    "    \n",
    "    # train vectorial model\n",
    "    regVectorial = sk.ensemble.RandomForestRegressor(n_estimators=1)\n",
    "    dfTrainBasis = dfVectorial[(dfVectorial[\"openmlid\"] != openmlid) & (dfVectorial[\"numinstances\"] != fitsize) & (dfVectorial[\"numattributes\"] != fitattributes)]\n",
    "    X_train = dfTrainBasis.drop(columns=[\"openmlid\", \"fittime\", \"apptimeperkinstances\"])\n",
    "    Y_train = dfTrainBasis[\"fittime\"] + dfTrainBasis[\"apptimeperkinstances\"]\n",
    "    invalidIndices = np.isnan(Y_train)\n",
    "    X_train = X_train[~invalidIndices]\n",
    "    Y_train = Y_train[~invalidIndices]\n",
    "    regVectorial.fit(X_train, Y_train)\n",
    "    print(\"Training finished\")\n",
    "    \n",
    "    for i, row in dfValidation.iterrows():\n",
    "        \n",
    "        origRow = dfPipelinesMod.iloc[i]\n",
    "        if str(origRow[\"baseclassifier\"]) in [\"decisionstump\", \"kstar\", \"naivebayesmultinomial\", \"zeror\"]:\n",
    "            print(origRow[\"baseclassifier\"])\n",
    "            continue\n",
    "        #if str(origRow[\"metaclassifier\"]) != \"nan\": # ignore pipelines with meta-learner\n",
    "            #print(\"meta\")\n",
    "            #continue\n",
    "        \n",
    "        if not np.isnan(row[\"fittime\"]) and row[\"fittime\"] > 10000:\n",
    "            \n",
    "            \n",
    "            #print(origRow)\n",
    "            #print(origRow[\"fittime\"] + origRow[\"apptimeperkinstances\"])\n",
    "            \n",
    "            # now make with the vectorial RF\n",
    "            X_test = row.drop(labels=[\"openmlid\", \"fittime\", \"apptimeperkinstances\"])\n",
    "            Y_test = row[\"fittime\"] + row[\"apptimeperkinstances\"]\n",
    "            Y_pred = regVectorial.predict([X_test])\n",
    "            pred_error_rf = (Y_test - Y_pred)[0] / 1000\n",
    "            \n",
    "            if Y_test < 3600000:\n",
    "\n",
    "                # now make with the composed model\n",
    "                if str(origRow[\"searcher\"]) != \"nan\":\n",
    "                    preprocessor = (origRow[\"searcher\"] + \"_\" + origRow[\"evaluator\"], str(origRow[\"searcheroptions\"]) + \";\" + str(origRow[\"evaluatoroptions\"] if str(origRow[\"evaluatoroptions\"]) != \"nan\" else \"\"))\n",
    "                else:\n",
    "                    preprocessor = None\n",
    "                #print(origRow[\"searcher\"], preprocessor)\n",
    "                F = reg.predictRuntime(origRow[\"openmlid\"], origRow[\"numinstances\"], origRow[\"numattributes\"], 1000, baselearner=(origRow[\"baseclassifier\"], origRow[\"baseclassifieroptions\"]), preprocessor=preprocessor)\n",
    "                A = Y_test\n",
    "                pred_error_comp = (A - F) / 1000\n",
    "\n",
    "                comp_here = [pred_error_rf, pred_error_comp]\n",
    "                COMPARISON.append(comp_here)\n",
    "                print(origRow[\"evaluator\"], origRow[\"metaclassifier\"], origRow[\"baseclassifier\"], Y_test, Y_pred, \"error rf:\", pred_error_rf, \"error comp:\", pred_error_comp)\n",
    "                #print(origRow[\"numinstances\"], origRow[\"numattributes\"], \"truth:\", int( / 1000), \"prediction:\", int(F / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfComparison = pd.DataFrame(COMPARISON, columns=[\"rf\", \"comp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfComparison.to_csv(\"data/results/pipelinecomparison.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x7f11218afb50>,\n",
       "  <matplotlib.lines.Line2D at 0x7f11218b40d0>,\n",
       "  <matplotlib.lines.Line2D at 0x7f11218bcb10>,\n",
       "  <matplotlib.lines.Line2D at 0x7f11218c4050>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x7f11218b4610>,\n",
       "  <matplotlib.lines.Line2D at 0x7f11218b4b50>,\n",
       "  <matplotlib.lines.Line2D at 0x7f11218c4510>,\n",
       "  <matplotlib.lines.Line2D at 0x7f11218c4a10>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x7f11218af610>,\n",
       "  <matplotlib.lines.Line2D at 0x7f11218bc610>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x7f11218bc110>,\n",
       "  <matplotlib.lines.Line2D at 0x7f11218c4f10>],\n",
       " 'fliers': [],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD4CAYAAADo30HgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQIUlEQVR4nO3dcaidd33H8ffHxHVlrprYqFmSLgWDrBWn9NAFhLHZjoYxTDcs5B8bWCFYKijsj7UrTGUMFEGh21oIVJpKZw3qaFDLrNXhP7H1RjrbpGZeVrSXBnslWRsZlKV+98f9Bc4vOblpcs69597k/YKH85zv7/k953fIyfmc5/k9555UFZIknfamaQ9AkrSyGAySpI7BIEnqGAySpI7BIEnqrJ32AMZ19dVX19atW6c9DElaVQ4dOvSrqtowqm3VB8PWrVuZmZmZ9jAkaVVJ8vNztXkqSZLUMRgkSR2DQZLUMRgkSR2DQZLUGTsYkvx2kqeT/GeSw0k+0+rrkzyR5Gftdt1Qn3uSzCY5muSWofoNSZ5tbfclybjjkyRdmEkcMbwGfKiq/hB4P7AjyXbgbuDJqtoGPNnuk+Q6YBdwPbADuD/JmravB4A9wLa27JjA+CRJF2DsYKgFv25339yWAnYC+1p9H3BrW98JPFpVr1XVC8AscGOSjcBVVXWwFv4W+MNDfSRJy2QicwxJ1iR5BngZeKKqngLeWVXHANrtO9rmm4AXh7rPtdqmtn5mfdTj7Ukyk2Rmfn5+Ek/hspLkohZJl4eJBENVvV5V7wc2s/Dp/72LbD7qHaYWqY96vL1VNaiqwYYNI7/RrUVU1TmXxdolXR4melVSVf0P8B8szA38sp0eot2+3DabA7YMddsMvNTqm0fUJUnLaBJXJW1I8ra2fiVwM/BT4ACwu222G3isrR8AdiW5Ism1LEwyP91ON51Msr1djXT7UB9J0jKZxB/R2wjsa1cWvQnYX1XfTHIQ2J/kDuAXwG0AVXU4yX7gCHAKuKuqXm/7uhN4CLgSeLwtkqRllNV+7ngwGJR/XXVykjifIF0GkhyqqsGoNr/5LEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqGAySpI7BIEnqjB0MSbYk+X6S55McTvKJVl+f5IkkP2u364b63JNkNsnRJLcM1W9I8mxruy9Jxh2fJOnCTOKI4RTwN1X1B8B24K4k1wF3A09W1TbgyXaf1rYLuB7YAdyfZE3b1wPAHmBbW3ZMYHySpAswdjBU1bGq+nFbPwk8D2wCdgL72mb7gFvb+k7g0ap6rapeAGaBG5NsBK6qqoNVVcDDQ30kSctkonMMSbYCHwCeAt5ZVcdgITyAd7TNNgEvDnWba7VNbf3M+qjH2ZNkJsnM/Pz8JJ+CJF32JhYMSd4CfB34ZFW9utimI2q1SP3sYtXeqhpU1WDDhg0XPlhJ0jlNJBiSvJmFUHikqr7Ryr9sp4doty+3+hywZaj7ZuClVt88oi5JWkaTuCopwIPA81X1haGmA8Dutr4beGyovivJFUmuZWGS+el2uulkku1tn7cP9ZEkLZO1E9jHB4GPAs8meabV/g74LLA/yR3AL4DbAKrqcJL9wBEWrmi6q6peb/3uBB4CrgQeb4skaRll4QKg1WswGNTMzMy0h3HJSMJqf01IOr8kh6pqMKrNbz5LkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoTCYYkX0rycpLnhmrrkzyR5Gftdt1Q2z1JZpMcTXLLUP2GJM+2tvuSZBLjkyS9cZM6YngI2HFG7W7gyaraBjzZ7pPkOmAXcH3rc3+SNa3PA8AeYFtbztynJGmJTSQYquoHwPEzyjuBfW19H3DrUP3Rqnqtql4AZoEbk2wErqqqg1VVwMNDfSRJy2Qp5xjeWVXHANrtO1p9E/Di0HZzrbaprZ9ZP0uSPUlmkszMz89PfOCSdDmbxuTzqHmDWqR+drFqb1UNqmqwYcOGiQ5Oki53SxkMv2ynh2i3L7f6HLBlaLvNwEutvnlEXZK0jJYyGA4Au9v6buCxofquJFckuZaFSean2+mmk0m2t6uRbh/qI0laJmsnsZMkXwH+BLg6yRzwKeCzwP4kdwC/AG4DqKrDSfYDR4BTwF1V9Xrb1Z0sXOF0JfB4WyRJyygLFwCtXoPBoGZmZqY9jEtGElb7a0LS+SU5VFWDUW1+81mS1DEYJEkdg0GS1DEYJEkdg0GS1DEYJEkdg0GS1DEYJEkdg0GS1DEYJEkdg0GS1DEYJEkdg0GS1DEYJEkdg0GS1DEYJEkdg0GS1DEYJEmdifzmsyRNSpIL7uPP0U6WwSBpRTnXm7y/R758PJUkSeqsuGBIsiPJ0SSzSe6e9nhWs/Xr15PkghbggrZfv379lJ+lpElbUaeSkqwB/gX4M2AO+FGSA1V1ZLojW51OnDix5IfeF3M+WIKFDy4nTpy4oD4X+npbt24dx48fv6A+WmHBANwIzFbVfwMkeRTYCRgMF6E+dRV8+q1L/xjSRfCDy8q10oJhE/Di0P054I/O3CjJHmAPwDXXXLM8I1uF8plXl+U/Xn16SR9Clyg/uKxcKy0YRsX7We9sVbUX2AswGAy8TEFahfKZV5f8MdatW8fxTy/5w1xyVlowzAFbhu5vBl6a0lgkLaELPZr1ctXls9KuSvoRsC3JtUl+C9gFHJjymCTpsrKijhiq6lSSjwP/DqwBvlRVh6c8LEm6rKyoYACoqm8D3572OCTpcrXigkHS5W2xS0zP1ebcw2QZDJJWFN/kp2+lTT5LkqbMYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVJnrGBIcluSw0l+k2RwRts9SWaTHE1yy1D9hiTPtrb70n7dO8kVSb7a6k8l2TrO2CRJF2fcI4bngL8CfjBcTHIdsAu4HtgB3J9kTWt+ANgDbGvLjla/AzhRVe8Gvgh8bsyxSZIuwljBUFXPV9XREU07gUer6rWqegGYBW5MshG4qqoOVlUBDwO3DvXZ19a/Btx0+mhCkrR8lmqOYRPw4tD9uVbb1NbPrHd9quoU8Arw9lE7T7InyUySmfn5+QkPXZIub2vPt0GS7wLvGtF0b1U9dq5uI2q1SH2xPmcXq/YCewEGg8HIbSRJF+e8wVBVN1/EfueALUP3NwMvtfrmEfXhPnNJ1gJvBY5fxGNLksawVKeSDgC72pVG17Iwyfx0VR0DTibZ3uYPbgceG+qzu61/BPhem4eQJC2j8x4xLCbJXwL/BGwAvpXkmaq6paoOJ9kPHAFOAXdV1eut253AQ8CVwONtAXgQ+HKSWRaOFHaNMzZJ0sXJav9QPhgMamZmZtrDWJGSsNT/vsvxGJImL8mhqhqMavObz5KkjsEgSeoYDJKkjsEgSeoYDJKkjsEgSeoYDJKkjsEgSeoYDJKkjsEgSeoYDJKkjsEgSeoYDJKkjsEgSeoYDJKkjsEgSeoYDJKkjsEgSeoYDJKkjsEgSeqsnfYAtLSSLOn+161bt6T7l7T8xjpiSPL5JD9N8pMk/5bkbUNt9ySZTXI0yS1D9RuSPNva7kt750pyRZKvtvpTSbaOMzZBVV3wcqH9jh8/PuVnKWnSxj2V9ATw3qp6H/BfwD0ASa4DdgHXAzuA+5OsaX0eAPYA29qyo9XvAE5U1buBLwKfG3NskqSLMFYwVNV3qupUu/tDYHNb3wk8WlWvVdULwCxwY5KNwFVVdbAWPp4+DNw61GdfW/8acFOW+jyIJOksk5x8/mvg8ba+CXhxqG2u1Ta19TPrXZ8WNq8Abx/1QEn2JJlJMjM/Pz+xJyBJegOTz0m+C7xrRNO9VfVY2+Ze4BTwyOluI7avReqL9Tm7WLUX2AswGAxGbiNJujjnDYaqunmx9iS7gb8AbqrTs5cLRwJbhjbbDLzU6ptH1If7zCVZC7wVcGZTkpbZuFcl7QD+FvhwVf3vUNMBYFe70uhaFiaZn66qY8DJJNvb/MHtwGNDfXa39Y8A3xsKGknSMhn3ewz/DFwBPNHmiX9YVR+rqsNJ9gNHWDjFdFdVvd763Ak8BFzJwpzE6XmJB4EvJ5ll4Uhh15hjkyRdhKz2D+WDwaBmZmamPYxLRhJW+2tC0vklOVRVg1Ft/kkMSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVLHYJAkdQwGSVJnrGBI8g9JfpLkmSTfSfJ7Q233JJlNcjTJLUP1G5I829ruS5JWvyLJV1v9qSRbxxmbJOnijHvE8Pmqel9VvR/4JvD3AEmuA3YB1wM7gPuTrGl9HgD2ANvasqPV7wBOVNW7gS8CnxtzbJKkizBWMFTVq0N3fweotr4TeLSqXquqF4BZ4MYkG4GrqupgVRXwMHDrUJ99bf1rwE2njyYkSctn7bg7SPKPwO3AK8CftvIm4IdDm8212v+19TPrp/u8CFBVp5K8Arwd+NWIx9zDwlEH11xzzbhPQZI05LxHDEm+m+S5EctOgKq6t6q2AI8AHz/dbcSuapH6Yn3OLlbtrapBVQ02bNhwvqcgSboA5z1iqKqb3+C+/hX4FvApFo4Etgy1bQZeavXNI+oM9ZlLshZ4K3D8DT62JGlCxr0qadvQ3Q8DP23rB4Bd7Uqja1mYZH66qo4BJ5Nsb/MHtwOPDfXZ3dY/AnyvzUNIkpbRuHMMn03yHuA3wM+BjwFU1eEk+4EjwCngrqp6vfW5E3gIuBJ4vC0ADwJfTjLLwpHCrjHHJkm6CFntH8oHg0HNzMxMexiXjCSs9teEpPNLcqiqBqPa/OazJKljMEiSOgaDJKljMEiSOgaDJKljMEiSOgaDJKljMEiSOgaDJKljMEiSOgaDJKljMEiSOmP/gptWn/P9Yuq52v3jetLlwWC4DPkGL2kxnkqSJHUMBklSx2CQJHUMBklSx2CQJHUMBklSx2CQJHUMBklSJ6v9y05J5oGfT3scl5CrgV9NexDSCL42J+v3q2rDqIZVHwyarCQzVTWY9jikM/naXD6eSpIkdQwGSVLHYNCZ9k57ANI5+NpcJs4xSJI6HjFIkjoGgySpYzAIgCRfSvJykuemPRZpWJItSb6f5Pkkh5N8YtpjutQ5xyAAkvwx8Gvg4ap677THI52WZCOwsap+nOR3gUPArVV1ZMpDu2R5xCAAquoHwPFpj0M6U1Udq6oft/WTwPPApumO6tJmMEhaNZJsBT4APDXdkVzaDAZJq0KStwBfBz5ZVa9OezyXMoNB0oqX5M0shMIjVfWNaY/nUmcwSFrRkgR4EHi+qr4w7fFcDgwGAZDkK8BB4D1J5pLcMe0xSc0HgY8CH0ryTFv+fNqDupR5uaokqeMRgySpYzBIkjoGgySpYzBIkjoGgySpYzBIkjoGgySp8/8D/LkiTH9DvQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(dfComparison.values, 0, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([946.96321218, 178.01102781])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.stats.trim_mean(np.abs(dfComparison.values), 0.05, axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
